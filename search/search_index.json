{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Snowman! Have you ever gotten a newsletter twice? Probably - finding duplicates in data is a pretty difficult problem. Many different algorithms exist with different approaches and tradeoffs. However, not only finding duplicates is difficult but also finding a deduplication algorithm for a dataset or even just comparing two different deduplication solutions. With our benchmark, we aim to solve exactly this challenge. This tool is developed as part of a bachelor's project in collaboration with SAP SE. Basic usage If you want to use our benchmark as a normal user, please consult the section Basic usage for details. Development setup If you intend to contribute to our project, please take a look at the Development setup section. It includes some basic information how to get started. Licenses Copyright 2021 Hasso Plattner Institute. Licensed under the MIT license. A complete list of all dependencies and their individual licenses can be found here: Licenses JSON","title":"Home"},{"location":"#welcome-to-snowman","text":"Have you ever gotten a newsletter twice? Probably - finding duplicates in data is a pretty difficult problem. Many different algorithms exist with different approaches and tradeoffs. However, not only finding duplicates is difficult but also finding a deduplication algorithm for a dataset or even just comparing two different deduplication solutions. With our benchmark, we aim to solve exactly this challenge. This tool is developed as part of a bachelor's project in collaboration with SAP SE.","title":"Welcome to Snowman!"},{"location":"#basic-usage","text":"If you want to use our benchmark as a normal user, please consult the section Basic usage for details.","title":"Basic usage"},{"location":"#development-setup","text":"If you intend to contribute to our project, please take a look at the Development setup section. It includes some basic information how to get started.","title":"Development setup"},{"location":"#licenses","text":"Copyright 2021 Hasso Plattner Institute. Licensed under the MIT license. A complete list of all dependencies and their individual licenses can be found here: Licenses JSON","title":"Licenses"},{"location":"basic_usage/benchmark/","text":"Benchmark This step is currently undergoing larger changes. At the moment, you can only do a binary comparison. The following benchmarking options are currently available to be used in Snowman: Binary Comparison For this step, the 1. experiment is considered to be the gold standard! After selecting this benchmarking option, binary metrics will be calculated and shown in the top carousel. You can step through all the available metrics cards and get an overview over the quality of the experiment. Keep in mind that these metrics are only as reliable as the gold standard is! Some metrics may be unreliable when calculated with a silver standard - our tool will highlight such metrics if the 1. experiment was flagged silver standard. Also, you'll be able to further inspect the experiment's performance by taking a look at the reported false negatives, false positives and true positives shown in the table below. Keep in mind that it may take some time to calculate the results shown on this page! Store a benchmarking setup It is planned for benchmarking setups to have the option to be saved somewhere for easier comparison. Sadly, this feature is not yet available and will be part of the larger changes that the whole benchmarking page will undergo.","title":"Benchmark"},{"location":"basic_usage/benchmark/#benchmark","text":"This step is currently undergoing larger changes. At the moment, you can only do a binary comparison. The following benchmarking options are currently available to be used in Snowman:","title":"Benchmark"},{"location":"basic_usage/benchmark/#binary-comparison","text":"For this step, the 1. experiment is considered to be the gold standard! After selecting this benchmarking option, binary metrics will be calculated and shown in the top carousel. You can step through all the available metrics cards and get an overview over the quality of the experiment. Keep in mind that these metrics are only as reliable as the gold standard is! Some metrics may be unreliable when calculated with a silver standard - our tool will highlight such metrics if the 1. experiment was flagged silver standard. Also, you'll be able to further inspect the experiment's performance by taking a look at the reported false negatives, false positives and true positives shown in the table below. Keep in mind that it may take some time to calculate the results shown on this page!","title":"Binary Comparison"},{"location":"basic_usage/benchmark/#store-a-benchmarking-setup","text":"It is planned for benchmarking setups to have the option to be saved somewhere for easier comparison. Sadly, this feature is not yet available and will be part of the larger changes that the whole benchmarking page will undergo.","title":"Store a benchmarking setup"},{"location":"basic_usage/datasets/","text":"Datasets Each workflow occurs upon a single dataset. As a first step, you'll have to specify a dataset. Add a dataset Open page \"Datasets\" from the sidebar on the left. Add a new dataset with the \"+\" button in the lower left corner of the screen. Specify a short identifying name and a comprehensive description. If you do not want to upload the complete dataset, select \"Skeleton only\" as contents and specify the total amount of tuples by hand. This is important to be able to still calculate metrics. If you want to upload the dataset, select \"Full upload\" as contents, specify the csv parameters and select a file to upload. Click on \"Add dataset\" - this process may take several minutes to complete as indexes have to be created! Upload failed Since creating the dataset and uploading its contents are two separate steps, you may receive an error message stating that the file upload failed. In this case, the dataset itself was created (most likely) empty with no records. In this case, simply delete the dataset and start over again. Future versions will allow you to further differentiate and change the records later on.","title":"Datasets"},{"location":"basic_usage/datasets/#datasets","text":"Each workflow occurs upon a single dataset. As a first step, you'll have to specify a dataset.","title":"Datasets"},{"location":"basic_usage/datasets/#add-a-dataset","text":"Open page \"Datasets\" from the sidebar on the left. Add a new dataset with the \"+\" button in the lower left corner of the screen. Specify a short identifying name and a comprehensive description. If you do not want to upload the complete dataset, select \"Skeleton only\" as contents and specify the total amount of tuples by hand. This is important to be able to still calculate metrics. If you want to upload the dataset, select \"Full upload\" as contents, specify the csv parameters and select a file to upload. Click on \"Add dataset\" - this process may take several minutes to complete as indexes have to be created!","title":"Add a dataset"},{"location":"basic_usage/datasets/#upload-failed","text":"Since creating the dataset and uploading its contents are two separate steps, you may receive an error message stating that the file upload failed. In this case, the dataset itself was created (most likely) empty with no records. In this case, simply delete the dataset and start over again. Future versions will allow you to further differentiate and change the records later on.","title":"Upload failed"},{"location":"basic_usage/experiments/","text":"Experiments A dataset can consist of multiple experiments. An experiment is thereby considered as a single run of a matching solution which produces an output set. To ease the workflow, experiments have to be labeled with the matching solution that was used. The description can contain additional information on how this exact result was achived - e.g. a list of configuration parameters, or the time spent labeling data. Add an experiment Select a dataset. Open page \"Experiments\" from the sidebar on the left. Add a new experiment with the \"+\" button in the lower left corner of the screen. Specify a short and concise name, as well as a detailed description. Select a file containing the result set and choose the correct import format. (see below) Click on \"Add experiment\" - this process may take several minutes to complete as indexes have to be created! Upload failed Since creating the experiment and uploading its contents are two separate steps, you may receive an error message stating that the file upload failed. In this case, the experiment itself was created (most likely) empty with no pairs. In this case, simply delete the experiment and start over again. Selecting experiments You can select experiments to use for the further workflow steps by clicking on the gray square of each experiment card. Within the side menu on the left, you can then see the order in which the experiments will be used. For now, you'll have to select the experiment used as a gold standard in the following steps with 1. - this is compulsory! Import formats To ease the import process, Snowman understands several file formats out of the box. Those include: Pilot This file format was introduced with the initial prototype and is the easiest available format. Result sets can be uploaded as (comma-separated) csv files in UTF-8 encoding. We expect the csv file to have , as split character, \" as quote character and ' as escape character. The importer expects the csv to have the columns p1 and p2 . They should store the ids of the respective dataset tuples. The csv optionally can have a column named \"prediction\" which contains a 1 in case the pair was detected as duplicate - 0 otherwise. If this column is not present we assume that all listed tuples have been detected as duplicates (think: we automatically insert a column \"prediction\" and fill it with the value 1 everywhere). Following this, more columns may be specified with arbitrary content. See the following example: p1,p2,prediction,feat1,feat2,feat3,sum 2,1,1,0.3,0.4,0.4,2 1,2,1,0.3,0.4,0.4,2 4,3,1,0.3,0.4,0.4,2 3,4,1,0.3,0.4,0.4,3 6,5,1,0.3,0.5,0.4,3 5,6,1,0.3,0.5,0.4,3 8,7,1,0.3,0.5,0.4,2 7,8,1,0.3,0.5,0.4,2 10,9,1,0.3,0.5,0.4,2 9,10,1,0.3,0.4,0.4,2 12,11,1,0.3,0.4,0.4,2 11,12,1,0.3,0.4,0.4,8 14,13,1,0.3,0.4,0.4,8 13,14,1,0.3,0.4,0.4,8 16,15,1,0.3,0.4,0.4,8 15,16,1,0.3,0.4,0.4,2 ... Magellan The open-source matching solution Magellan is widely used in research. We support its result set file format out of the box. ,_id,ltable_id,rtable_id,id_id_exm,id_id_anm,id_id_lev_dist,id_id_lev_sim,name_name_jac_qgm_3_qgm_3,name_name_cos_dlm_dc0_dlm_dc0,name_name_jac_dlm_dc0_dlm_dc0,name_name_mel,name_name_lev_dist,name_name_lev_sim,name_name_nmw,name_name_sw,addr_addr_jac_qgm_3_qgm_3,addr_addr_cos_dlm_dc0_dlm_dc0,addr_addr_jac_dlm_dc0_dlm_dc0,addr_addr_mel,addr_addr_lev_dist,addr_addr_lev_sim,addr_addr_nmw,addr_addr_sw,city_city_jac_qgm_3_qgm_3,city_city_cos_dlm_dc0_dlm_dc0,city_city_jac_dlm_dc0_dlm_dc0,city_city_mel,city_city_lev_dist,city_city_lev_sim,city_city_nmw,city_city_sw,type_type_jac_qgm_3_qgm_3,type_type_cos_dlm_dc0_dlm_dc0,type_type_jac_dlm_dc0_dlm_dc0,type_type_mel,type_type_lev_dist,type_type_lev_sim,type_type_nmw,type_type_sw,gold,predicted 124,2054,598,283,0,0.47324414715719065,3,0.0,1.0,1.0,1.0,1.0,0.0,1.0,11.0,11.0,0.21739130434782608,0.40824829046386296,0.2222222222222222,0.7647619247436523,30.0,0.25,-16.0,9.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.4991452991962433,11.0,0.15384615384615385,-6.0,1.0,1,1 54,768,739,115,0,0.15561569688768606,3,0.0,0.1111111111111111,0.40824829046386296,0.25,0.5292929410934448,12.0,0.19999999999999996,-1.0,4.0,0.14814814814814814,0.2886751345948129,0.16666666666666666,0.5842490792274475,9.0,0.3571428571428571,4.0,4.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.0,6.0,0.0,-2.0,1.0,0,0 268,1736,1046,246,0,0.23518164435946465,2,0.5,0.058823529411764705,0.33333333333333337,0.2,0.5309057235717773,15.0,0.11764705882352944,0.0,4.0,0.06896551724137931,0.0,0.0,0.6170329451560974,10.0,0.2857142857142857,3.0,4.0,0.0,0.0,0.0,0.5897436141967773,10.0,0.23076923076923073,2.0,3.0,0.3,0.7071067811865475,0.5,0.875,10.0,0.375,-4.0,6.0,0,0 293,618,888,78,0,0.08783783783783783,2,0.33333333333333337,0.2,0.4999999999999999,0.3333333333333333,0.6702020168304443,9.0,0.4,2.0,5.0,0.10810810810810811,0.22360679774997896,0.125,0.510185182094574,17.0,0.29166666666666663,-2.0,6.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.5777778029441833,6.0,0.0,-1.0,1.0,0,0 230,486,866,66,0,0.07621247113163976,1,0.6666666666666667,0.18181818181818182,0.35355339059327373,0.2,0.35333332419395447,18.0,0.28,-8.0,6.0,0.02857142857142857,0.0,0.0,0.4783068895339966,14.0,0.2222222222222222,0.0,2.0,0.0,0.0,0.0,0.4611110985279083,13.0,0.1333333333333333,-5.0,1.0,0.0,0.0,0.0,0.5138888955116272,7.0,0.125,-2.0,2.0,0,0 134,2079,599,284,0,0.4741235392320534,3,0.0,1.0,1.0,1.0,1.0,0.0,1.0,17.0,17.0,1.0,1.0,1.0,1.0,0.0,1.0,14.0,14.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.4444444444444444,0.7071067811865475,0.5,0.9142857193946838,6.0,0.5714285714285714,2.0,8.0,1,1 12,391,905,48,0,0.053038674033149213,3,0.0,0.19230769230769232,0.40824829046386296,0.25,0.6499999761581421,9.0,0.4,3.0,6.0,0.023809523809523808,0.0,0.0,0.47883597016334534,18.0,0.1428571428571429,0.0,2.0,0.0,0.0,0.0,0.5416666865348816,9.0,0.25,-1.0,3.0,0.4444444444444444,0.7071067811865475,0.5,0.7321428656578064,6.0,0.5714285714285714,2.0,8.0,0,0 423,1450,758,209,0,0.2757255936675461,3,0.0,0.21875,0.35355339059327373,0.2,0.5888888835906982,12.0,0.4,3.0,7.0,0.07692307692307693,0.0,0.0,0.5629629492759705,11.0,0.2666666666666667,-2.0,4.0,0.0,0.0,0.0,0.5352563858032227,12.0,0.07692307692307687,-4.0,2.0,0.0,0.0,0.0,0.4833333194255829,8.0,0.19999999999999996,0.0,2.0,0,0 272,248,797,33,0,0.04140526976160597,3,0.0,0.20833333333333334,0.40824829046386296,0.25,0.6168830990791321,8.0,0.4285714285714286,3.0,6.0,0.2,0.5,0.3333333333333333,0.7516340017318726,9.0,0.47058823529411764,6.0,7.0,0.0,0.0,0.0,0.0,8.0,0.0,-6.0,0.0,1.0,1.0,1.0,1.0,0.0,1.0,8.0,8.0,0,0 ... Sigmod2021 See here . ClusterER This is an internal file format.","title":"Experiments"},{"location":"basic_usage/experiments/#experiments","text":"A dataset can consist of multiple experiments. An experiment is thereby considered as a single run of a matching solution which produces an output set. To ease the workflow, experiments have to be labeled with the matching solution that was used. The description can contain additional information on how this exact result was achived - e.g. a list of configuration parameters, or the time spent labeling data.","title":"Experiments"},{"location":"basic_usage/experiments/#add-an-experiment","text":"Select a dataset. Open page \"Experiments\" from the sidebar on the left. Add a new experiment with the \"+\" button in the lower left corner of the screen. Specify a short and concise name, as well as a detailed description. Select a file containing the result set and choose the correct import format. (see below) Click on \"Add experiment\" - this process may take several minutes to complete as indexes have to be created!","title":"Add an experiment"},{"location":"basic_usage/experiments/#upload-failed","text":"Since creating the experiment and uploading its contents are two separate steps, you may receive an error message stating that the file upload failed. In this case, the experiment itself was created (most likely) empty with no pairs. In this case, simply delete the experiment and start over again.","title":"Upload failed"},{"location":"basic_usage/experiments/#selecting-experiments","text":"You can select experiments to use for the further workflow steps by clicking on the gray square of each experiment card. Within the side menu on the left, you can then see the order in which the experiments will be used. For now, you'll have to select the experiment used as a gold standard in the following steps with 1. - this is compulsory!","title":"Selecting experiments"},{"location":"basic_usage/experiments/#import-formats","text":"To ease the import process, Snowman understands several file formats out of the box. Those include:","title":"Import formats"},{"location":"basic_usage/experiments/#pilot","text":"This file format was introduced with the initial prototype and is the easiest available format. Result sets can be uploaded as (comma-separated) csv files in UTF-8 encoding. We expect the csv file to have , as split character, \" as quote character and ' as escape character. The importer expects the csv to have the columns p1 and p2 . They should store the ids of the respective dataset tuples. The csv optionally can have a column named \"prediction\" which contains a 1 in case the pair was detected as duplicate - 0 otherwise. If this column is not present we assume that all listed tuples have been detected as duplicates (think: we automatically insert a column \"prediction\" and fill it with the value 1 everywhere). Following this, more columns may be specified with arbitrary content. See the following example: p1,p2,prediction,feat1,feat2,feat3,sum 2,1,1,0.3,0.4,0.4,2 1,2,1,0.3,0.4,0.4,2 4,3,1,0.3,0.4,0.4,2 3,4,1,0.3,0.4,0.4,3 6,5,1,0.3,0.5,0.4,3 5,6,1,0.3,0.5,0.4,3 8,7,1,0.3,0.5,0.4,2 7,8,1,0.3,0.5,0.4,2 10,9,1,0.3,0.5,0.4,2 9,10,1,0.3,0.4,0.4,2 12,11,1,0.3,0.4,0.4,2 11,12,1,0.3,0.4,0.4,8 14,13,1,0.3,0.4,0.4,8 13,14,1,0.3,0.4,0.4,8 16,15,1,0.3,0.4,0.4,8 15,16,1,0.3,0.4,0.4,2 ...","title":"Pilot"},{"location":"basic_usage/experiments/#magellan","text":"The open-source matching solution Magellan is widely used in research. We support its result set file format out of the box. ,_id,ltable_id,rtable_id,id_id_exm,id_id_anm,id_id_lev_dist,id_id_lev_sim,name_name_jac_qgm_3_qgm_3,name_name_cos_dlm_dc0_dlm_dc0,name_name_jac_dlm_dc0_dlm_dc0,name_name_mel,name_name_lev_dist,name_name_lev_sim,name_name_nmw,name_name_sw,addr_addr_jac_qgm_3_qgm_3,addr_addr_cos_dlm_dc0_dlm_dc0,addr_addr_jac_dlm_dc0_dlm_dc0,addr_addr_mel,addr_addr_lev_dist,addr_addr_lev_sim,addr_addr_nmw,addr_addr_sw,city_city_jac_qgm_3_qgm_3,city_city_cos_dlm_dc0_dlm_dc0,city_city_jac_dlm_dc0_dlm_dc0,city_city_mel,city_city_lev_dist,city_city_lev_sim,city_city_nmw,city_city_sw,type_type_jac_qgm_3_qgm_3,type_type_cos_dlm_dc0_dlm_dc0,type_type_jac_dlm_dc0_dlm_dc0,type_type_mel,type_type_lev_dist,type_type_lev_sim,type_type_nmw,type_type_sw,gold,predicted 124,2054,598,283,0,0.47324414715719065,3,0.0,1.0,1.0,1.0,1.0,0.0,1.0,11.0,11.0,0.21739130434782608,0.40824829046386296,0.2222222222222222,0.7647619247436523,30.0,0.25,-16.0,9.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.4991452991962433,11.0,0.15384615384615385,-6.0,1.0,1,1 54,768,739,115,0,0.15561569688768606,3,0.0,0.1111111111111111,0.40824829046386296,0.25,0.5292929410934448,12.0,0.19999999999999996,-1.0,4.0,0.14814814814814814,0.2886751345948129,0.16666666666666666,0.5842490792274475,9.0,0.3571428571428571,4.0,4.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.0,6.0,0.0,-2.0,1.0,0,0 268,1736,1046,246,0,0.23518164435946465,2,0.5,0.058823529411764705,0.33333333333333337,0.2,0.5309057235717773,15.0,0.11764705882352944,0.0,4.0,0.06896551724137931,0.0,0.0,0.6170329451560974,10.0,0.2857142857142857,3.0,4.0,0.0,0.0,0.0,0.5897436141967773,10.0,0.23076923076923073,2.0,3.0,0.3,0.7071067811865475,0.5,0.875,10.0,0.375,-4.0,6.0,0,0 293,618,888,78,0,0.08783783783783783,2,0.33333333333333337,0.2,0.4999999999999999,0.3333333333333333,0.6702020168304443,9.0,0.4,2.0,5.0,0.10810810810810811,0.22360679774997896,0.125,0.510185182094574,17.0,0.29166666666666663,-2.0,6.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.0,0.0,0.0,0.5777778029441833,6.0,0.0,-1.0,1.0,0,0 230,486,866,66,0,0.07621247113163976,1,0.6666666666666667,0.18181818181818182,0.35355339059327373,0.2,0.35333332419395447,18.0,0.28,-8.0,6.0,0.02857142857142857,0.0,0.0,0.4783068895339966,14.0,0.2222222222222222,0.0,2.0,0.0,0.0,0.0,0.4611110985279083,13.0,0.1333333333333333,-5.0,1.0,0.0,0.0,0.0,0.5138888955116272,7.0,0.125,-2.0,2.0,0,0 134,2079,599,284,0,0.4741235392320534,3,0.0,1.0,1.0,1.0,1.0,0.0,1.0,17.0,17.0,1.0,1.0,1.0,1.0,0.0,1.0,14.0,14.0,0.47058823529411764,0.8164965809277259,0.6666666666666666,0.9230769276618958,5.0,0.6153846153846154,3.0,8.0,0.4444444444444444,0.7071067811865475,0.5,0.9142857193946838,6.0,0.5714285714285714,2.0,8.0,1,1 12,391,905,48,0,0.053038674033149213,3,0.0,0.19230769230769232,0.40824829046386296,0.25,0.6499999761581421,9.0,0.4,3.0,6.0,0.023809523809523808,0.0,0.0,0.47883597016334534,18.0,0.1428571428571429,0.0,2.0,0.0,0.0,0.0,0.5416666865348816,9.0,0.25,-1.0,3.0,0.4444444444444444,0.7071067811865475,0.5,0.7321428656578064,6.0,0.5714285714285714,2.0,8.0,0,0 423,1450,758,209,0,0.2757255936675461,3,0.0,0.21875,0.35355339059327373,0.2,0.5888888835906982,12.0,0.4,3.0,7.0,0.07692307692307693,0.0,0.0,0.5629629492759705,11.0,0.2666666666666667,-2.0,4.0,0.0,0.0,0.0,0.5352563858032227,12.0,0.07692307692307687,-4.0,2.0,0.0,0.0,0.0,0.4833333194255829,8.0,0.19999999999999996,0.0,2.0,0,0 272,248,797,33,0,0.04140526976160597,3,0.0,0.20833333333333334,0.40824829046386296,0.25,0.6168830990791321,8.0,0.4285714285714286,3.0,6.0,0.2,0.5,0.3333333333333333,0.7516340017318726,9.0,0.47058823529411764,6.0,7.0,0.0,0.0,0.0,0.0,8.0,0.0,-6.0,0.0,1.0,1.0,1.0,1.0,0.0,1.0,8.0,8.0,0,0 ...","title":"Magellan"},{"location":"basic_usage/experiments/#sigmod2021","text":"See here .","title":"Sigmod2021"},{"location":"basic_usage/experiments/#clusterer","text":"This is an internal file format.","title":"ClusterER"},{"location":"basic_usage/introduction/","text":"Introduction Welcome to the Snowman Data Matching Benchmark - this guide aims to help you get started! Setup Download the latest artifact for you platform from the Github Releases page. Extract the zip somewhere safe (e.g. your Documents folder) and run snowman.exe , snowman.app or snowman according to the platform you are on. The benchmark will now start and ask you whether you want to spin up a local instance or connect to a remote. Local usage If you select local usage, a folder will be created within your home directory which houses our data store. This exact location of this folder is platform specific. Platform Folder macOS ~/Library/Application Support/snowman-wrapper Windows C:\\Users\\ \\AppData\\Local\\snowman-wrapper Linux ~/.config/snowman-wrapper If you changed something about your environment, these paths may be different. Rest assured that Snowman will not touch any other folders or files :) Remote usage If you received a link to a colleagues instance, enter the link into the shown input field. The app will now attempt to connect to this URL and if unsuccessful show an error message. Connection issues can have a lot of causes - as a first debug step, attempt to open the URL within your browser! Concepts As a first step, we suggest for you to get familiar with two of our main concepts - matching solutions and workflows.","title":"Introduction"},{"location":"basic_usage/introduction/#introduction","text":"Welcome to the Snowman Data Matching Benchmark - this guide aims to help you get started!","title":"Introduction"},{"location":"basic_usage/introduction/#setup","text":"Download the latest artifact for you platform from the Github Releases page. Extract the zip somewhere safe (e.g. your Documents folder) and run snowman.exe , snowman.app or snowman according to the platform you are on. The benchmark will now start and ask you whether you want to spin up a local instance or connect to a remote.","title":"Setup"},{"location":"basic_usage/introduction/#local-usage","text":"If you select local usage, a folder will be created within your home directory which houses our data store. This exact location of this folder is platform specific. Platform Folder macOS ~/Library/Application Support/snowman-wrapper Windows C:\\Users\\ \\AppData\\Local\\snowman-wrapper Linux ~/.config/snowman-wrapper If you changed something about your environment, these paths may be different. Rest assured that Snowman will not touch any other folders or files :)","title":"Local usage"},{"location":"basic_usage/introduction/#remote-usage","text":"If you received a link to a colleagues instance, enter the link into the shown input field. The app will now attempt to connect to this URL and if unsuccessful show an error message. Connection issues can have a lot of causes - as a first debug step, attempt to open the URL within your browser!","title":"Remote usage"},{"location":"basic_usage/introduction/#concepts","text":"As a first step, we suggest for you to get familiar with two of our main concepts - matching solutions and workflows.","title":"Concepts"},{"location":"basic_usage/matching_solutions/","text":"Matching Solutions As a first step, a new user should register matching solutions with the tool, since it is compulsory for an experiment to be associated with a matching solution. Add a solution Open page \"Matching solutions\" from the sidebar on the left. Add a new solution with the \"+\" button in the lower left corner of the screen. Specify a short name (without spaces if possible) and a comprehensive description. Delete a solution If a solution was created by accident or is not required anymore, you can delete it. Keep in mind that you'll have to delete all associated experiments first! Example Imagine you are running the Magellan data matching tool (open-source). It allows you to configure several aspects of how it operates and thereby a lot of customization is possible. For this use case, you'd only create one matching solution \"Magellan\" within the tool (use a general description, e.g. ML-based open-source approach). For each configuration, you can afterwards create a new experiment containing information on the configuration within its description.","title":"Matching solutions"},{"location":"basic_usage/matching_solutions/#matching-solutions","text":"As a first step, a new user should register matching solutions with the tool, since it is compulsory for an experiment to be associated with a matching solution.","title":"Matching Solutions"},{"location":"basic_usage/matching_solutions/#add-a-solution","text":"Open page \"Matching solutions\" from the sidebar on the left. Add a new solution with the \"+\" button in the lower left corner of the screen. Specify a short name (without spaces if possible) and a comprehensive description.","title":"Add a solution"},{"location":"basic_usage/matching_solutions/#delete-a-solution","text":"If a solution was created by accident or is not required anymore, you can delete it. Keep in mind that you'll have to delete all associated experiments first!","title":"Delete a solution"},{"location":"basic_usage/matching_solutions/#example","text":"Imagine you are running the Magellan data matching tool (open-source). It allows you to configure several aspects of how it operates and thereby a lot of customization is possible. For this use case, you'd only create one matching solution \"Magellan\" within the tool (use a general description, e.g. ML-based open-source approach). For each configuration, you can afterwards create a new experiment containing information on the configuration within its description.","title":"Example"},{"location":"basic_usage/workflow/","text":"Workflow Each comparison setup within the benchmark tool is considered a workflow. This means that a single workflow consists of a dataset, multiple experiments as well as a benchmark option. Workflows are managed implicitly, so you do not need to create a new one each time you want to reconfigure the comparison setup. Basic setup Select a dataset. Select multiple experiments. Decide upon a benchmark to run. (Currently \"Binary Comparison\" is the only option and therefore selected by default!) Assumptions Each workflow occurs on exactly one dataset. It is not possible to compare different datasets it later steps of a workflow. Changing the datasets after e.g. experiments where selected will reset the workflow starting from scratch with the new dataset.","title":"Workflow"},{"location":"basic_usage/workflow/#workflow","text":"Each comparison setup within the benchmark tool is considered a workflow. This means that a single workflow consists of a dataset, multiple experiments as well as a benchmark option. Workflows are managed implicitly, so you do not need to create a new one each time you want to reconfigure the comparison setup.","title":"Workflow"},{"location":"basic_usage/workflow/#basic-setup","text":"Select a dataset. Select multiple experiments. Decide upon a benchmark to run. (Currently \"Binary Comparison\" is the only option and therefore selected by default!)","title":"Basic setup"},{"location":"basic_usage/workflow/#assumptions","text":"Each workflow occurs on exactly one dataset. It is not possible to compare different datasets it later steps of a workflow. Changing the datasets after e.g. experiments where selected will reset the workflow starting from scratch with the new dataset.","title":"Assumptions"},{"location":"dev_setup/introduction/","text":"Development setup This page is not finished yet! Please get in touch in case you want to start developing :) The project is split into 3 (or 4) individual components which need special care. Attention: You'll need a working C++ compiler installed and added to your PATH variable. The easiest way to accomplish this is installing the VisualStudio BuildTools for C++ (incl. a reboot). Folder structure To ease development, the benchmark is split into three separate packages. See the following details for more information. ./ This folder includes the global linter for Typescript and CSS. Install the dependencies with npm install . You may now execute npm run lint or npm run lint-fix - or any other script defined in package.json :) npm start will build and run everything combined :) ./app Our React frontend is contained in this folder. Open a terminal within it and run npm install as well. ./wrapper To wrap everything and build a single binary, electron is used. This also includes the backend which consists of a Node Express server. npm install installs the dependencies :) Backend API The backend can also be reached directly. See our guide \"REST API\" for details.","title":"Introduction"},{"location":"dev_setup/introduction/#development-setup","text":"This page is not finished yet! Please get in touch in case you want to start developing :) The project is split into 3 (or 4) individual components which need special care. Attention: You'll need a working C++ compiler installed and added to your PATH variable. The easiest way to accomplish this is installing the VisualStudio BuildTools for C++ (incl. a reboot).","title":"Development setup"},{"location":"dev_setup/introduction/#folder-structure","text":"To ease development, the benchmark is split into three separate packages. See the following details for more information.","title":"Folder structure"},{"location":"dev_setup/introduction/#_1","text":"This folder includes the global linter for Typescript and CSS. Install the dependencies with npm install . You may now execute npm run lint or npm run lint-fix - or any other script defined in package.json :) npm start will build and run everything combined :)","title":"./"},{"location":"dev_setup/introduction/#app","text":"Our React frontend is contained in this folder. Open a terminal within it and run npm install as well.","title":"./app"},{"location":"dev_setup/introduction/#wrapper","text":"To wrap everything and build a single binary, electron is used. This also includes the backend which consists of a Node Express server. npm install installs the dependencies :)","title":"./wrapper"},{"location":"dev_setup/introduction/#backend-api","text":"The backend can also be reached directly. See our guide \"REST API\" for details.","title":"Backend API"},{"location":"showcase/main/","text":"Showcase This page contains some screenshots from our data matching benchmark - the Snowman App!","title":"Showcase"},{"location":"showcase/main/#showcase","text":"This page contains some screenshots from our data matching benchmark - the Snowman App!","title":"Showcase"}]}